{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "located-solid",
   "metadata": {},
   "source": [
    "# Goal<br>\n",
    "* Develop a machine learning model using bag of words and vectorization that will take in Netflix descriptions of shows in it's database and predict wether the show matching each discription belongs to a given genre<br>\n",
    "\n",
    "* Inestigate wether this technique can be inhanced by identifying \"unique words,\" words that only occur in discriptions belonging to that genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "southeast-mineral",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "\n",
    "import unicodedata\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "import sklearn.preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import wrangle as w\n",
    "import explore as e\n",
    "import model as m\n",
    "\n",
    "#pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protecting-ethics",
   "metadata": {},
   "source": [
    "# Wrangle\n",
    "\n",
    "Data acquired from kaggle \n",
    "Each represints a show featured by Netflix\n",
    "\n",
    "Columns not representing show descriptions or genres were dropped\n",
    "A boolean column for each genre appearing in the \"genres\" column was added signifying if each show belonged to that genre\n",
    "\n",
    "Rows containning blank descriptions were dropped\n",
    "'Western' column was dropped do to low represintation (only 41 rows)\n",
    "\n",
    "Data contains 5791 rows after being prepared \n",
    "\n",
    "Note:\n",
    "    \n",
    "* adding words two letters and fewer to those removed by stopwords, on next iteration investigate for useful words\n",
    "* using raw counts for frequency measure, on next iteration consider using percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "modified-timothy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set contains 3242 rows of data\n",
      "Validate set contains 1390 rows of data\n",
      "Test set contains 1159 rows of data\n"
     ]
    }
   ],
   "source": [
    "#acquire and prepare data\n",
    "df = w.get_show_data()\n",
    "\n",
    "# split data into train, validate and prep\n",
    "train, validate, test = w.split_my_data(df)\n",
    "\n",
    "# get set of non-western genres\n",
    "gen_set = e.get_gens(train)\n",
    "\n",
    "# print number ow rows in train\n",
    "print(f\"Train set contains {train.shape[0]} rows of data\")\n",
    "print(f\"Validate set contains {validate.shape[0]} rows of data\")\n",
    "print(f\"Test set contains {test.shape[0]} rows of data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "capital-surge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>genres</th>\n",
       "      <th>crime</th>\n",
       "      <th>documentation</th>\n",
       "      <th>history</th>\n",
       "      <th>action</th>\n",
       "      <th>horror</th>\n",
       "      <th>scifi</th>\n",
       "      <th>music</th>\n",
       "      <th>reality</th>\n",
       "      <th>european</th>\n",
       "      <th>thriller</th>\n",
       "      <th>comedy</th>\n",
       "      <th>fantasy</th>\n",
       "      <th>war</th>\n",
       "      <th>romance</th>\n",
       "      <th>animation</th>\n",
       "      <th>family</th>\n",
       "      <th>sport</th>\n",
       "      <th>drama</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>crippling payday loan car cheat emission test ...</td>\n",
       "      <td>[documentation, crime]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>filmmaker kip andersen uncovers secret prevent...</td>\n",
       "      <td>[documentation]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>azerbaijan layla indonesian scholar fall samir...</td>\n",
       "      <td>[romance, drama]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quebec impulsive headstrong nelly maloye novic...</td>\n",
       "      <td>[animation, comedy]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hit hardwood east los angeles coach strong con...</td>\n",
       "      <td>[documentation, sport]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description                  genres  \\\n",
       "0  crippling payday loan car cheat emission test ...  [documentation, crime]   \n",
       "1  filmmaker kip andersen uncovers secret prevent...         [documentation]   \n",
       "2  azerbaijan layla indonesian scholar fall samir...        [romance, drama]   \n",
       "3  quebec impulsive headstrong nelly maloye novic...     [animation, comedy]   \n",
       "4  hit hardwood east los angeles coach strong con...  [documentation, sport]   \n",
       "\n",
       "   crime  documentation  history  action  horror  scifi  music  reality  \\\n",
       "0   True           True    False   False   False  False  False    False   \n",
       "1  False           True    False   False   False  False  False    False   \n",
       "2  False          False    False   False   False  False  False    False   \n",
       "3  False          False    False   False   False  False  False    False   \n",
       "4  False           True    False   False   False  False  False    False   \n",
       "\n",
       "   european  thriller  comedy  fantasy    war  romance  animation  family  \\\n",
       "0     False     False   False    False  False    False      False   False   \n",
       "1     False     False   False    False  False    False      False   False   \n",
       "2     False     False   False    False  False     True      False   False   \n",
       "3     False     False    True    False  False    False       True   False   \n",
       "4     False     False   False    False  False    False      False   False   \n",
       "\n",
       "   sport  drama  \n",
       "0  False  False  \n",
       "1  False  False  \n",
       "2  False   True  \n",
       "3  False  False  \n",
       "4   True  False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "mobile-finance",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['description_lem'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8ef058851ab0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'display.max_colwidth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'description'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'description_lem'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3462\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3463\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3464\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3466\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1312\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1314\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m         if needs_i8_conversion(ax.dtype) or isinstance(\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis)\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1377\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['description_lem'] not in index\""
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cathedral-actress",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spiritual-footage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting exploration variables\n",
    "\n",
    "# gets dictionaries \n",
    "# containing word, relative requency of apearance in comedy and non-comedy films by count and by document count \n",
    "# and a list for each containing frequency numbers only\n",
    "freq_doc, freq_count, list_freq_doc, list_freq_count = e.get_majoriety_counts(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-printing",
   "metadata": {},
   "source": [
    "# Explore\n",
    "\n",
    "**1) Investigate data and choose a genre as a test case**\n",
    "\n",
    "   * Test case should have a large represintation in the data\n",
    "   * Test case should have a large number of unique words\n",
    "   * Test case should have a large number of unique words per document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wireless-cycle",
   "metadata": {},
   "source": [
    "**How many shows are there of each genre?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-portable",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get distribution of genres\n",
    "e.shows_per_gen(train, gen_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consistent-cartridge",
   "metadata": {},
   "source": [
    "Comedy and Drama seem to be the front runners."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governmental-scenario",
   "metadata": {},
   "source": [
    "**How many words in each genre are unique words? (Appear only in descriptions of movies of that fall under that genre)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-receipt",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get number of unique words fro each genre\n",
    "e.unique_words_per_gen(train, gen_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indie-intelligence",
   "metadata": {},
   "source": [
    "Comedy and Drama seem to be the front runners for unique words as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-vegetarian",
   "metadata": {},
   "source": [
    "**How fequently do unique words appear in each genre?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-choice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get frequency of unique words pre genre\n",
    "e.unique_words_frequency(train, gen_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amended-principal",
   "metadata": {},
   "source": [
    "Not a great deal of variance in unique word frequency. Comedy and Drama both have grater than three they were front runners in the other two criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-coverage",
   "metadata": {},
   "source": [
    "**Comedy** and **Drama** have consistantly high values in all test criteria.\n",
    "Comedy seems the less vague of the two genres, by human understanding. I will choose **Comedy** as my test case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alert-floating",
   "metadata": {},
   "source": [
    "**2) Investigate test case (Comedy) and see how it compares to the rest of the data**\n",
    "\n",
    "* What percent of the data is classified as a Comedy?\n",
    "* Are there any words that appear more or less frequently across comedy or non-comedy show descriptions? <br>(Overall/by document)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-divide",
   "metadata": {},
   "source": [
    "**How much of the data is Comedy?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-edwards",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "e.omni_pie(train.comedy, \"40% of the Training Data are Comedy Titles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proud-makeup",
   "metadata": {},
   "source": [
    "**Can we use the relative frequency of words in descriptions to seperate noise from signal?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-administrator",
   "metadata": {},
   "source": [
    "**The following chart shows a histogram of the relative document frequency of each unique word appearing in film descriptions**\n",
    "<br>\n",
    "The number is calculated in the following way: <br>\n",
    "number of comedy documents the word appears in minus the number of non-comedy documents the word appears in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-upper",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.get_hist_doc(list_freq_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "described-advance",
   "metadata": {},
   "source": [
    "* Data appears to normalize around 0 however the steps are steeper on the positive side\n",
    "* Skew is likely do to the 60/40 imbalance in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finnish-movie",
   "metadata": {},
   "source": [
    "**The following chart shows the relative frequency of each unique word appearing film descriptions**\n",
    "The number is calculated in the following way: <br>\n",
    "number of times the word appears in comedy documents minus number of times the word appears in non-comedy documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-executive",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.get_hist_word(list_freq_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instrumental-doubt",
   "metadata": {},
   "source": [
    "* Data appears to normalize around -2 and there seems to be more negative values than positive ones\n",
    "* Skew is likely do to the 60/40 imbalance in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crucial-genre",
   "metadata": {},
   "source": [
    "Words that do not have a significant difference in apearances between comedy and non-comedy films will not be useful in guiding the model. Looking at the results of these distributions tells me that once the data is vectorized there will be a lot of noise words that can be dropped to make sure that signal words are having a stronger impact on the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compound-fantasy",
   "metadata": {},
   "source": [
    "**As a quick sanity test lets take a look at our top 15 most extream values for document and word frequency**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signal-dining",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.get_doc_ext(dict(freq_doc[:15]), \"Top 15 Most Extreme Negative Document Frequency Values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-roommate",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.get_doc_ext(dict(freq_count[:15]), \"Top 15 Most Extreme Negative Word Frequency Values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addressed-unemployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.get_doc_ext(dict(freq_doc[-15:]), \"Top 15 Most Extreme Positive Document Frequency Values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-claim",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.get_doc_ext(dict(freq_count[-15:]), \"Top 15 Most Extreme Positive Document Frequency Values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forward-anger",
   "metadata": {},
   "source": [
    "* Extreme negative values seem suspect due to the imbalance in the data words commen to both comedy and non-comedy films may have a large negative value because there are more non-comedy films in the data.\n",
    "* Extreme positive value words are intuatively indicitive of the comedy genre and servive in spite of the data imbalance working against them. They seem like good indicators."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statewide-rabbit",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "I will be examining different tequniques for building the most accurate possible model. Techniques include using word count vs TF-IDF, differint machine learning classification models, and a number of feature engineering ideas. For this reason models will be graded on overall accuracy above all. Ties will be decided by fewist false negatives. As a buisness case, it seems better to me to present a movie to a customer out of genre then to fail to present an in ingenre film that might increase that customers watchtime, provided these occurances are kept to a minimum.\n",
    "Because the data has a 60/40 split my beginning baseline is 60% and will hopefully be improved on throughout the modeling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endless-twelve",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate train, validate and test data into X (description) and y (comedy) \n",
    "train_X = train[['description']].reset_index(drop=True)\n",
    "train_y = train[['comedy']].reset_index(drop=True)\n",
    "\n",
    "validate_X = validate[['description']].reset_index(drop=True)\n",
    "validate_y = validate[['comedy']].reset_index(drop=True)\n",
    "\n",
    "test_X = test[['description']].reset_index(drop=True)\n",
    "test_y = test[['comedy']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incredible-angel",
   "metadata": {},
   "source": [
    "## Count Analysis - Full Vectorization Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lasting-ending",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_counts, validate_counts, test_counts = m.get_counts(train_X, validate_X, test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-cable",
   "metadata": {},
   "outputs": [],
   "source": [
    "#m.get_acc_table(train_counts, train_y, validate_counts, validate_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrow-century",
   "metadata": {},
   "source": [
    "When predicting on raw counts the logistic regression and random forest models both broke 70% accuracy. Lets see if I can improve on that by cutting out some of the noise. For the next two attempts I will drop all of the words that with a 0 relative frequency for document and raw count frequency. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "false-syria",
   "metadata": {},
   "source": [
    "## Count Analysis - Drop 0 Relative Frequency - Raw Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floppy-democrat",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_counts.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bearing-chassis",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_counts['wilson']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generous-walker",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_lst = []\n",
    "\n",
    "for freq in freq_count:\n",
    "    \n",
    "    if freq[1] == 0:\n",
    "        \n",
    "        drop_lst.append(freq[0])\n",
    "\n",
    "\n",
    "print(len(train_counts), len(drop_lst))\n",
    "\n",
    "for \n",
    "train_counts.drop(columns=drop_lst, inplace = True)\n",
    "validate_counts.drop(columns=drop_lst)\n",
    "\n",
    "print(len(train_counts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polished-banner",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
